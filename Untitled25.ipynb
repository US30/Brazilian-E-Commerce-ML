{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FIPvMAhEzQ4O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Load all 9 CSV files ---\n",
        "print(\"Step 1: Loading all 9 CSV files...\")\n",
        "df_orders = pd.read_csv(\"olist_orders_dataset.csv\")\n",
        "df_reviews = pd.read_csv(\"olist_order_reviews_dataset.csv\")\n",
        "df_items = pd.read_csv(\"olist_order_items_dataset.csv\")\n",
        "df_payments = pd.read_csv(\"olist_order_payments_dataset.csv\")\n",
        "df_products = pd.read_csv(\"olist_products_dataset.csv\")\n",
        "df_sellers = pd.read_csv(\"olist_sellers_dataset.csv\")\n",
        "df_customers = pd.read_csv(\"olist_customers_dataset.csv\")\n",
        "df_geo = pd.read_csv(\"olist_geolocation_dataset.csv\")\n",
        "df_translation = pd.read_csv(\"product_category_name_translation.csv\")\n",
        "print(\"All files loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Nj5klS0H-M",
        "outputId": "dbf1e2b5-3145-4eb8-ca6f-676a0c8bd48e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Loading all 9 CSV files...\n",
            "All files loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Aggregate Payments ---\n",
        "# An order can have multiple payment methods (e.g., voucher + credit_card).\n",
        "# We'll aggregate them to the order level.\n",
        "print(\"\\nStep 2: Processing Payments...\")\n",
        "# Find the most common payment type for each order\n",
        "df_payment_type = df_payments.loc[df_payments.groupby('order_id')['payment_sequential'].idxmax()][['order_id', 'payment_type']]\n",
        "\n",
        "# Aggregate payment data\n",
        "df_payments_agg = df_payments.groupby('order_id').agg(\n",
        "    total_payment_value=('payment_value', 'sum'),\n",
        "    total_payment_installments=('payment_installments', 'sum'),\n",
        "    num_payment_methods=('payment_sequential', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# Merge the most common payment type\n",
        "df_payments_agg = pd.merge(df_payments_agg, df_payment_type, on='order_id', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-fnDlTd0Lfy",
        "outputId": "77f7a967-7a0b-4722-85a5-ea18b69d3e8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2: Processing Payments...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Aggregate Items/Products/Sellers ---\n",
        "print(\"\\nStep 3: Processing Items, Products, and Sellers...\")\n",
        "\n",
        "# 3a. Merge products with their English translation\n",
        "df_products_translated = pd.merge(df_products, df_translation, on='product_category_name', how='left')\n",
        "\n",
        "# 3b. Merge items with product and seller info\n",
        "df_items_full = pd.merge(df_items, df_products_translated, on='product_id', how='left')\n",
        "df_items_full = pd.merge(df_items_full, df_sellers, on='seller_id', how='left')\n",
        "\n",
        "# 3c. Create product volume feature\n",
        "df_items_full['product_volume_cm3'] = df_items_full['product_length_cm'] * df_items_full['product_height_cm'] * df_items_full['product_width_cm']\n",
        "\n",
        "# 3d. Aggregate item/product data by order_id\n",
        "df_items_agg = df_items_full.groupby('order_id').agg(\n",
        "    total_price=('price', 'sum'),\n",
        "    total_freight_value=('freight_value', 'sum'),\n",
        "    num_items=('order_item_id', 'count'),\n",
        "    avg_product_weight_g=('product_weight_g', 'mean'),\n",
        "    avg_product_volume_cm3=('product_volume_cm3', 'mean'),\n",
        "    num_sellers=('seller_id', 'nunique'),\n",
        "    avg_photos_qty=('product_photos_qty', 'mean'),\n",
        "    avg_product_name_length=('product_name_lenght', 'mean'),\n",
        "    avg_product_description_length=('product_description_lenght', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# 3e. Get location of the *first* seller for each order (for distance calculation)\n",
        "df_seller_location = df_items_full.loc[df_items_full['order_item_id'] == 1][[\n",
        "    'order_id',\n",
        "    'seller_zip_code_prefix',\n",
        "    'seller_state'\n",
        "]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpEPvT6e1E73",
        "outputId": "964d064d-e9ba-4f63-8568-423ecc80a1c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: Processing Items, Products, and Sellers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Pre-process Geolocation ---\n",
        "# The geo file has ~1M rows but only ~19K unique zip codes.\n",
        "# We'll create one average lat/lng for each zip code prefix.\n",
        "print(\"\\nStep 4: Processing Geolocation data...\")\n",
        "df_geo_agg = df_geo.groupby('geolocation_zip_code_prefix').agg(\n",
        "    geo_lat=('geolocation_lat', 'mean'),\n",
        "    geo_lng=('geolocation_lng', 'mean')\n",
        ").reset_index()\n",
        "print(f\"Geolocation data reduced from {len(df_geo)} to {len(df_geo_agg)} unique zip codes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5wYG1vI1KoD",
        "outputId": "57b84e2d-3ef4-42b4-d8db-e5032082c150"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 4: Processing Geolocation data...\n",
            "Geolocation data reduced from 1000163 to 19015 unique zip codes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Build Master Table ---\n",
        "print(\"\\nStep 5: Building Master Table...\")\n",
        "\n",
        "# 5a. Start with the 'orders' table.\n",
        "# We'll filter for 'delivered' orders, as they are the only ones with a complete lifecycle.\n",
        "df_master = df_orders[df_orders['order_status'] == 'delivered'].copy()\n",
        "print(f\"Started with {len(df_orders)} orders, filtered to {len(df_master)} 'delivered' orders.\")\n",
        "\n",
        "# 5b. Merge with reviews. We use 'inner' join to keep only orders that have a review.\n",
        "# The review_score is our target variable (y).\n",
        "df_master = pd.merge(df_master, df_reviews[['order_id', 'review_score']], on='order_id', how='inner')\n",
        "\n",
        "# 5c. Merge with customer info\n",
        "df_master = pd.merge(df_master, df_customers[['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']], on='customer_id', how='left')\n",
        "\n",
        "# 5d. Merge with aggregated payments\n",
        "df_master = pd.merge(df_master, df_payments_agg, on='order_id', how='left')\n",
        "\n",
        "# 5e. Merge with aggregated items\n",
        "df_master = pd.merge(df_master, df_items_agg, on='order_id', how='left')\n",
        "\n",
        "# 5f. Merge with the first-seller location info\n",
        "df_master = pd.merge(df_master, df_seller_location, on='order_id', how='left')\n",
        "print(f\"Master table created with {len(df_master)} rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaaXR2G-1Ohx",
        "outputId": "8d8e3cc2-a796-4e15-d618-ba5bf49a70c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Building Master Table...\n",
            "Started with 99441 orders, filtered to 96478 'delivered' orders.\n",
            "Master table created with 96361 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Feature Engineering ---\n",
        "print(\"\\nStep 6: Feature Engineering...\")\n",
        "\n",
        "# 6a. Convert timestamp columns to datetime objects\n",
        "time_cols = [\n",
        "    'order_purchase_timestamp',\n",
        "    'order_approved_at',\n",
        "    'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date',\n",
        "    'order_estimated_delivery_date'\n",
        "]\n",
        "for col in time_cols:\n",
        "    df_master[col] = pd.to_datetime(df_master[col])\n",
        "\n",
        "# 6b. Create time-based features (in days)\n",
        "df_master['delivery_time_days'] = (df_master['order_delivered_customer_date'] - df_master['order_purchase_timestamp']).dt.total_seconds() / (24 * 60 * 60)\n",
        "df_master['estimated_delivery_time_days'] = (df_master['order_estimated_delivery_date'] - df_master['order_purchase_timestamp']).dt.total_seconds() / (24 * 60 * 60)\n",
        "df_master['shipping_time_days'] = (df_master['order_delivered_customer_date'] - df_master['order_delivered_carrier_date']).dt.total_seconds() / (24 * 60 * 60)\n",
        "df_master['approval_time_days'] = (df_master['order_approved_at'] - df_master['order_purchase_timestamp']).dt.total_seconds() / (24 * 60 * 60)\n",
        "df_master['days_to_ship'] = (df_master['order_delivered_carrier_date'] - df_master['order_approved_at']).dt.total_seconds() / (24 * 60 * 60)\n",
        "\n",
        "# 6c. Create 'is_late' feature\n",
        "df_master['is_late'] = (df_master['order_delivered_customer_date'] > df_master['order_estimated_delivery_date']).astype(int)\n",
        "\n",
        "# 6d. Create 'freight_ratio' feature\n",
        "df_master['freight_ratio'] = df_master['total_freight_value'] / df_master['total_price']\n",
        "# Replace any infinite values (if price was 0) with 0\n",
        "df_master['freight_ratio'].replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "\n",
        "# 6e. Extract temporal features from purchase timestamp\n",
        "df_master['purchase_day_of_week'] = df_master['order_purchase_timestamp'].dt.dayofweek\n",
        "df_master['purchase_month'] = df_master['order_purchase_timestamp'].dt.month\n",
        "df_master['purchase_hour'] = df_master['order_purchase_timestamp'].dt.hour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp2tR_hB1UIE",
        "outputId": "b9301a35-47ed-4b36-ec02-2d643e78678d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 6: Feature Engineering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-229972021.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_master['freight_ratio'].replace([np.inf, -np.inf], 0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Calculate Seller-Customer Distance ---\n",
        "print(\"\\nStep 7: Calculating Seller-Customer Distance...\")\n",
        "\n",
        "# 7a. Merge with geo data for customer\n",
        "df_master = pd.merge(\n",
        "    df_master,\n",
        "    df_geo_agg,\n",
        "    left_on='customer_zip_code_prefix',\n",
        "    right_on='geolocation_zip_code_prefix',\n",
        "    how='left'\n",
        ")\n",
        "df_master.rename(columns={'geo_lat': 'customer_lat', 'geo_lng': 'customer_lng'}, inplace=True)\n",
        "df_master.drop('geolocation_zip_code_prefix', axis=1, inplace=True)\n",
        "\n",
        "# 7b. Merge with geo data for seller\n",
        "df_master = pd.merge(\n",
        "    df_master,\n",
        "    df_geo_agg,\n",
        "    left_on='seller_zip_code_prefix',\n",
        "    right_on='geolocation_zip_code_prefix',\n",
        "    how='left'\n",
        ")\n",
        "df_master.rename(columns={'geo_lat': 'seller_lat', 'geo_lng': 'seller_lng'}, inplace=True)\n",
        "df_master.drop('geolocation_zip_code_prefix', axis=1, inplace=True)\n",
        "\n",
        "# 7c. Define Haversine function to calculate distance in km\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # Earth radius in kilometers\n",
        "\n",
        "    # Check for NaNs before conversion\n",
        "    if any(pd.isna([lat1, lon1, lat2, lon2])):\n",
        "        return np.nan\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# 7d. Calculate distance\n",
        "# Note: .apply() can be slow. A vectorized numpy approach is faster,\n",
        "# but this is more readable and matches the logic used.\n",
        "print(\"Calculating Haversine distance (this may take a minute)...\")\n",
        "df_master['seller_customer_distance_km'] = df_master.apply(\n",
        "    lambda row: haversine(\n",
        "        row['customer_lat'],\n",
        "        row['customer_lng'],\n",
        "        row['seller_lat'],\n",
        "        row['seller_lng']\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "print(\"Distance calculation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_5H1XVY1YB-",
        "outputId": "9c839081-db66-4565-a897-63685cff7443"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 7: Calculating Seller-Customer Distance...\n",
            "Calculating Haversine distance (this may take a minute)...\n",
            "Distance calculation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 8: Final Cleanup and Preprocessing ---\n",
        "print(\"\\nStep 8: Final Cleanup and Preprocessing...\")\n",
        "\n",
        "# 8a. Select columns for the final ML dataset\n",
        "target_col = 'review_score'\n",
        "\n",
        "numeric_features = [\n",
        "    'total_payment_value', 'total_payment_installments', 'num_payment_methods',\n",
        "    'total_price', 'total_freight_value', 'num_items',\n",
        "    'avg_product_weight_g', 'avg_product_volume_cm3', 'num_sellers',\n",
        "    'avg_photos_qty', 'avg_product_name_length', 'avg_product_description_length',\n",
        "    'delivery_time_days', 'estimated_delivery_time_days', 'shipping_time_days',\n",
        "    'approval_time_days', 'days_to_ship', 'is_late', 'freight_ratio',\n",
        "    'purchase_day_of_week', 'purchase_month', 'purchase_hour',\n",
        "    'seller_customer_distance_km'\n",
        "]\n",
        "\n",
        "categorical_features = ['payment_type', 'customer_state', 'seller_state']\n",
        "\n",
        "columns_to_keep = [target_col] + numeric_features + categorical_features\n",
        "df_ml = df_master[columns_to_keep].copy()\n",
        "print(f\"Kept {len(df_ml.columns)} columns for the final dataset.\")\n",
        "\n",
        "# 8b. Handle Missing Values\n",
        "print(\"Handling missing values...\")\n",
        "\n",
        "# For numeric features, fill with the median\n",
        "for col in numeric_features:\n",
        "    if df_ml[col].isnull().any():\n",
        "        median_val = df_ml[col].median()\n",
        "        df_ml[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# For categorical features, fill with 'unknown'\n",
        "for col in categorical_features:\n",
        "    if df_ml[col].isnull().any():\n",
        "        df_ml[col].fillna('unknown', inplace=True)\n",
        "\n",
        "# 8c. One-Hot Encode Categorical Features\n",
        "print(\"One-hot encoding categorical features...\")\n",
        "df_ml = pd.get_dummies(df_ml, columns=categorical_features, drop_first=True)\n",
        "print(f\"Dataset shape after one-hot encoding: {df_ml.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwwSyo2W1cX8",
        "outputId": "11d745dc-3e33-428d-f6e7-58d48597425e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 8: Final Cleanup and Preprocessing...\n",
            "Kept 27 columns for the final dataset.\n",
            "Handling missing values...\n",
            "One-hot encoding categorical features...\n",
            "Dataset shape after one-hot encoding: (96361, 75)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2060407349.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_ml[col].fillna(median_val, inplace=True)\n",
            "/tmp/ipython-input-2060407349.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_ml[col].fillna('unknown', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8d. Final check\n",
        "print(f\"Total remaining NaN values: {df_ml.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zse1BfZ1io9",
        "outputId": "9434bf1b-efb0-472c-babf-768a30dcb23d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total remaining NaN values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8e. Save the final dataset\n",
        "print(\"\\nSaving the final ML-ready dataset to 'final_ml_dataset.csv'...\")\n",
        "df_ml.to_csv('final_ml_dataset.csv', index=False)\n",
        "\n",
        "print(\"\\n--- All Done! 'final_ml_dataset.csv' is ready. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgQPoG0H1mek",
        "outputId": "04bc2f4b-fe63-4f88-fe99-29456df3024d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving the final ML-ready dataset to 'final_ml_dataset.csv'...\n",
            "\n",
            "--- All Done! 'final_ml_dataset.csv' is ready. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HwLfFQrm1oaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}